\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}


\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%


\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\chapter{Appendix E: Examples of Multivariable Thinking}
\vspace{-.53in}
   \noindent\color{graylight}\rule[0cm]{3.25in}{0.03cm} \\
    \noindent\color{graylight}\rule[0.4cm]{3.25in}{0.03cm} \\
\color{black}
\vspace{-.25in}

\section{\textbf{Introduction}}

Issues of confounding and bias arise commonly in many analyses that are labeled as data science.  
%They need repeated exposure to the
%analysis of data to build their skills.

Simple multivariable methods are sometimes excluded from introductory statistics courses.
These approaches represent an area where statistics bring great value, since
issues of design, confounding, and bias are important for the analyses of experiments and 
observational studies.

Students are generally taught that
if data arise from well conducted randomized trials, they can make causal conclusions using a two-sample t-test. 
All too often, this is considered the pinnacle of statistics.
But most data that students see are not derived from a randomized trial with no dropout, full adherence, and sufficient blinding.  In these situations, students may be stymied by courses that only consider bivariate relationships.
A concern is that students may be paralyzed by what is likely their only statistics course \cite{meng:2011}
and not see the full potential for statistics as a foundation
for learning from data.


The new ASA guidelines for undergraduate programs in statistics state that
students need a clear understanding of principles of statistical design
and tools to assess and account for the possible impact of
other
measured and unmeasured variables \cite{asa:2014}.
This can't all happen in a single statistics course, but it is important that students are exposed to the basic principles
early and often.

The long laundry-list of possible topics for the first course along with expectations from client disciplines make it challenging to bring multivariate thinking into the mix.
What can we teach students in the first course?  

In this appendix we consider two simple examples where ``other factors" may arise where appropriate analyses can be undertaken through stratification.  Such an approach requires no inferential methods or advanced methods (though some instructors may incorporate other related concepts and approaches). 

\section{\textbf{Smoking in Whickham}}


Consider an example where statewide data from the mid-1990's are used to assess the association between average teacher salary in the state and average SAT (Scholastic Aptitude Test) scores for students \cite{gube:1999}.  These exams are used for college entry, and the results are sometimes used as a proxy for educational quality.  The leftmost
graph in Figure \ref{fig:sat} displays the unconditional association between these variables.  There is a statistically significant negative relationship. The model predicts that a state with an average salary that is one thousand dollars
higher than another would have SAT scores that are 5.54 points [95\% CI 8.82 to 2.26] lower.

\begin{figure}[tbh]
\begin{center}
<<message=FALSE>>=
require(mosaic); require(mosaicData)
trellis.par.set(theme=col.mosaic(bw=TRUE)); options(digits=3)

mod1 = lm(sat ~ salary, data=SAT); confint(mod1)

mod2 = lm(sat ~ salary + frac, data=SAT); confint(mod2)

SAT = transform(SAT, fracgrp = cut(frac, breaks=c(0, 22, 49, 81),
labels=c("low fraction", "medium fraction", "high fraction")))
plot1 = xyplot(sat ~ salary, type=c("r", "p"),
               xlab="Average teacher salary",
               ylab="State average SAT score", data=SAT)
@
\caption{Left: unconditional association of state average teacher salary with average SAT score; Right: association after accounting for the fraction of students taking the SAT in that state}
\label{fig:sat}
\end{center}
\end{figure}

But the real story is hidden behind one of the ``other factors" that we warn students about but don't generally teach how to address!  The proportion of students taking the SAT varies dramatically by region, as do teacher salaries.
In the midwest and plains states, where teacher salaries tend to be lower, relatively few high school students take the SAT exam.  These are
typically the top students who are planning to attend college out of state, while many others take the
alternative standardized ACT test.  The net result is that the fraction
taking the SAT is a confounding factor.  In a multiple regression model that controls for this variable, the
sign of the slope parameter flips.  The new model predicts that a state with an average salary that is one
thousand dollars higher than another would expect to have SAT scores that are 2.18 points higher [95\% CI 0.11 to  4.25].

This problem is a continuous example of Simpson's paradox.
There is no automated data mining or machine learning methods that can get close to the right answer if the stratifying variable is not collected. However, statistical thinking with an appreciation of Simpson's paradox would alert a student to \emph{look for} the hidden confounding variables.
To tackle this problem, students need to understand multivariable modeling.

One natural approach to develop such understanding is multiple regression.
While this is not a traditional topic included in introductory statistics, an increasing number of textbooks
and courses are incorporating the basic principles (often purely as a descriptive summarization of the data).

Another option for this analysis is even simpler: the use of stratification.
We can arbitrarily split the states up into groups based on the fraction of
students taking the SAT.  The rightmost scatterplot in Figure \ref{fig:sat} displays a grouping of
states with 0-22\% of students (``low fraction", top line), 23-49\% of students (``medium fraction", middle line), and
50-81\% (``high fraction", bottom line). The story is clear: there is a positive or flat relationship between teacher salary
and SAT score for each of these groups, but when we average over them, we observe a negative relationship.

Shattuck would have recognized this problem: the mortality estimates in Figure \ref{fig:shattuck}
are multivariate, with discrete strata of sub-populations.
This type of multivariable thinking is critical to make sense of the observational data around us.  If students
don't see some tools for disentangling complex relationships, they may dismiss statistics as an old-school
discipline only suitable for small sample inference of randomized studies.
Without a background in these key design topics,
data scientists may make errors in their interpretations.


Find the least squares \marginnote{\textit{Critique: Made-up data with no context (not recommended). The problem is purely computational with no possibility of meaningful interpretation.}} line for the data below.  Use it to predict Y when X=5.


\begin{table}[!ht]
\begin{center}
\begin{tabular}{|l|l|l|l|l|l|l|}
\hline
X & 1 & 2 & 3 & 4 & 6 & 8\\
\hline
Y & 3 & 4 & 6 & 7 & 14 & 20\\
\hline
\end{tabular}
\end{center}
\end{table}



\section{\textbf{Realistic Data (better, but still not the best)}}

The data below show\marginnote{\textit{Critique: A context has been added that makes the exercise more appealing and shows students a practical use of statistics.}} the number of customers in each of six tables at a restaurant and the size of the tip left at each table at the end of the meal.  Use the data to find a least squares line for predicting the size of the tip from the number of diners at the table.  Use your result to predict the size of the tip at a table that has five diners. 

\begin{table}[!ht]
\begin{center}
\begin{tabular}{|l|c|c|c|c|c|c|}
\hline
Diners & 1 & 2 & 3 & 4 & 6 & 8\\
\hline
Tip & \$3 & \$4 & \$6 & \$7 & \$14 & \$20\\
\hline
\end{tabular}
\end{center}
\end{table}


\newpage
\section{\textbf{Real Data (recommended)}}

The data below\marginnote{\textit{Critique: Data are from a real situation that should be of interest to students taking the course.}}  show the quiz scores (out of 20) and the grades on the midterm exam (out of 100) for a sample of eight students who took this course last semester.  Use these data to find a least squares line for predicting the midterm score from the quiz score. 
Assuming the quiz and midterm are of equal difficulty this semester and the same linear relationship applies this year, what is the predicted grade on the midterm for a student who got a score of 17 on the quiz? 

\begin{table}[!ht]
\begin{center}
\begin{tabular}{|l|l|l|l|l|l|l|l|l|}
\hline
Quiz & 20 & 15 & 13 & 18 & 18 & 20 & 14 & 16\\
\hline
Midterm & 92 & 72 & 72 & 95 & 88 & 98 & 65 & 77\\
\hline
\end{tabular}
\end{center}
\end{table}

