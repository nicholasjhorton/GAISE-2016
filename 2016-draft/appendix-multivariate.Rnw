\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}

\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%


\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\chapter{Appendix E: Multivariable Thinking}
\vspace{-.53in}
   \noindent\color{graylight}\rule[0cm]{3.25in}{0.03cm} \\
    \noindent\color{graylight}\rule[0.4cm]{3.25in}{0.03cm} \\
\color{black}
\vspace{-.25in}

\section{\textbf{Introduction}}

The new ASA guidelines for undergraduate programs in statistics recommend that students obtain a clear understanding of principles of statistical design and tools to assess and account for the possible impact of other measured and unmeasured confounding variables\cite{asa:2014}. 
\marginnote{See also Wild's ``On locating statistics in the world of finding out", \url{http://arxiv.org/abs/1507.05982.}}%
An introductory statistics course cannot cover these topics in depth, but it is important to expose students to them even in their first course\cite{meng:2011}.

Perhaps the best place to start is to consider how a third variable can change our understanding of the relationship between two variables. 

In this appendix we offer two simple examples where ``other factors" may arise where appropriate analyses can be undertaken through stratification. Such an approach requires no advanced methods, nor even any inference (though some instructors may incorporate other related concepts and approaches). These examples can help to introduce students to these concepts\marginnote{The \emph{Journal of Statistics Education} Datasets and Stories department features a number of interesting multivariable examples that feature confounding.}.

What is especially concerning in a first (and often only) statistics course is that the simple examples we use to introduce statistics concepts can give students the false impression that all data come from well-conducted randomized trials with no dropout, full adherence, and sufficient blinding and that regression models always include all the appropriate predictors. We hope that introductory statistics courses can open students' eyes to the complexity of real data and the need to take that complexity into account.

Including one or more multivariable examples early in an introductory statistics course may help to prepare students to deal with more than one or two variables at a time.


\section{\textbf{Smoking in Whickham}}


A follow-up study of 1,314 people in Whickham, England characterized smoking
status at baseline, then mortality after 10 years\cite{appl:1996}.  The data are provided in 
Table \ref{tab:whick1}.

\begin{table}[!ht]
\begin{center}
\begin{tabular}{|l|l|l|}
\hline
SMOKER & Alive & Dead \\ \hline
No & 502 (68.6\%) & 230 (31.4\%) \\ \hline
Yes & 443 (76.1\%) & 139 (23.9\%) \\ \hline
\end{tabular}
\caption{Distribution of smoking status and mortality status (after ten years) from the Whickham study}
\label{tab:whick1}
\end{center}
\end{table}

We see that the risk of dying is lower for smokers than for non-smokers, since 
31.4\% of the non-smokers died, but only 23.9\% of the smokers did not survive over the ten year period.  

A graphical representation using a mosaicplot (also known as an \emph{Eikosogram}) represents the cell 
probabilities as a function of area.  

\begin{figure}[tbhp]
<<whick1,warning=FALSE, fig.height=3.8,message=FALSE,echo=FALSE>>=
require(gmodels); require(mosaic)
Whickham <- mutate(Whickham,
                   agegrp = cut(age, breaks=c(1, 44, 64, 100), labels=c("18-44", "45-64", "65+")))
mosaicplot(tally(~ outcome + smoker, data=Whickham), ylab="Smoking status", 
  xlab="Mortality status (after 10 years)", main="", color=TRUE)
# with(Whickham, CrossTable(smoker, outcome, prop.c=FALSE, prop.chisq=FALSE, prop.t=FALSE))
@
\caption{Mosaicplot representing the association between smoking status and mortality in the Whickham
study}
\label{fig:whick1}
\end{figure}

We note that the majority of subjects have survived, but that
the area for the smokers who are still alive is larger than we would expect if there were no 
association between these variables.
What could explain this result?

Let's consider stratification by age of the participants.  Table \ref{tab:whick2} and Figure \ref{fig:whick2} displays the relationship
between smoking and mortality over a 10--year period for those age 18--44, those 45-64, and subjects that were 65 or older at baseline.
\begin{table}[!ht]
\begin{center}
\begin{tabular}{|l|l|l|l|}
\hline
Baseline age & SMOKER & Alive & Dead \\ \hline \hline
18-44 & No & 327 (96.5\%) & 12 (3.5\%) \\  \hline
18-44 & Yes & 270 (94.7\%) & 15 (5.3\%) \\ \hline \hline
45-64 & No & 147 (73.5\%) & 53 (26.5\%) \\ \hline
45-64 & Yes & 167 (67.6\%) & 80 (32.4\%) \\ \hline \hline
65+ & No & 28 (14.5\%) & 165 (85.5\%) \\ \hline
65+ & Yes & 6 (12.0\%) & 44 (88.0\%) \\ \hline 
\end{tabular}
\caption{Distribution of smoking status and mortality status (after 10 years) stratified by age (at baseline) from the Whickham study}
\label{tab:whick2}
\end{center}
\end{table}

\begin{figure}[h]
\includegraphics{includes/Whickham.pdf}
\caption{Mosaicplot representing the association between mortality and smoking status (stratified by baseline age) in the Whickham study}
\label{fig:whick2}
\end{figure}

<<whick2,warning=FALSE, message=FALSE,echo=FALSE>>=
require(gmodels); require(mosaic)
#with(filter(Whickham, agegrp=="18-44"), CrossTable(smoker, outcome, prop.c=FALSE, prop.chisq=FALSE, prop.t=FALSE))
@

We see that mortality rates are low for the youngest group, but the mortality rate is slightly higher for smokers than non-smokers (5.3\% for smokers vs 3.5\% for non-smokers).  (Given such low baserates, the information value of the first of the three stratified mosaicplots is low.)

Similar results are seen 
for subjects who are between 45--64 years old at baseline: smokers have a higher
probability of mortality than non-smokers.
\marginnote{Smoking is ``bad" within each of the subgroups of age, while smoking is ``good" overall.}
Almost all of the participants who were 65 or older at baseline died during the followup period, but the 
probability of dying was also slightly higher for smokers than non-smokers.

This example represents a classic example of \emph{Simpson's paradox}\cite{simp:1951}, where 
overall smoking appears to be ``protective", but within each age group smokers have a higher probability
of dying than non-smokers.



How can this be happening?  Figure \ref{fig:whickage1} and Table \ref{tab:whickage1} help
us to disentangle these relationships.  

\begin{figure}[tbhp]
<<whickage1,warning=FALSE, fig.height=3.8,message=FALSE,echo=FALSE>>=
mosaicplot(tally(~ agegrp + outcome, data=Whickham), ylab="mortality status (after 10 years)", 
  xlab="Age group", main="", color=TRUE)
#with(Whickham, CrossTable(agegrp, smoker, prop.c=FALSE, prop.chisq=FALSE, prop.t=FALSE))
@
\caption{Mosaicplot representing the association between mortality and age in the Whickham
study}
\label{fig:whickage1}
\end{figure}


\begin{table}[htpb]
\begin{center}
\begin{tabular}{|l|l|l|}
\hline
Age group & Alive & Dead \\ \hline
18-44 & 597 (95.7\%) & 27 (4.3\%) \\ \hline
45-64 & 314 (70.2\%) & 133 (29.8\%) \\ \hline
65+ & 34 (14.0\%) & 209 (86.0\%) \\ \hline
\end{tabular}
\caption{Distribution of age group and mortality status (after 10 years) 
from the Whickham study}
\label{tab:whickage1}\end{center}
\end{table}

Not surprisingly, we see that
mortality rates are highest for the oldest subjects.

We also observe that 
there is an association between age group and smoking status, as displayed in 
Figure \ref{fig:whickage2} and Table \ref{tab:whickage2}.

\begin{figure}[tbhp]
<<whickage2,warning=FALSE, fig.height=3.8,message=FALSE,echo=FALSE>>=
mosaicplot(tally(~ agegrp + smoker, data=Whickham), ylab="smoking status", 
  xlab="Age group", main="", color=TRUE)
@
\caption{Mosaicplot representing the association between smoking status and age in the Whickham
study}
\label{fig:whickage2}
\end{figure}

\begin{table}[htpb]
\begin{center}
\begin{tabular}{|l|l|l|}
\hline
Age group & Non-smoker & Smoker \\ \hline
18-44 & 339 (54.3\%) & 285 (45.7\%) \\ \hline
45-64 & 200 (44.7\%) & 247 (55.3\%) \\ \hline
65+ & 193 (79.4\%) & 50 (20.6\%) \\ \hline
\end{tabular}
\caption{Distribution of age group and smoking status (at baseline) 
from the Whickham study}
\label{tab:whickage2}\end{center}
\end{table}

Smoking is also associated with age, with those between
the ages of 45 to 64 most likely to have been smokers at baseline.  


After controlling for age, smokers have a higher
rate of mortality than non-smokers in this study.
<<whick4,warning=FALSE, message=FALSE,echo=FALSE>>=
#with(filter(Whickham, agegrp=="65+"), CrossTable(smoker, outcome, prop.c=FALSE, prop.chisq=FALSE, prop.t=FALSE))
@


Simple methods such as stratification can allow students to think beyond two 
dimensions and reveal effects of confounding variables.  Introducing this
thought process early on helps students easily transition to analyses involving multiple explanatory variables.





\section{\textbf{SAT scores and teacher salaries}}

Consider an example where statewide data from the mid-1990's are used to assess the association between average teacher salary in the state and average SAT (Scholastic Aptitude Test) scores for students 
\cite{gube:1999} \cite{hort:2015}.  These high stakes high school exams are sometimes used as a proxy for educational quality.  
Figure \ref{fig:sat} displays the (unconditional) association between these variables.  There is a statistically significant negative relationship ($\hat{\beta_1}$=-5.54 points, $p=0.001$). The model predicts that a state with an average salary that is one thousand dollars
higher than another would have SAT scores that are on average 5.54 points lower.

\begin{figure}[tbhp]
\begin{center}
<<sat1,fig.height=3.5,fig.width=5.8,message=FALSE,echo=FALSE,warning=FALSE>>=
require(mosaic); require(mosaicData)
trellis.par.set(theme=col.mosaic(bw=TRUE)); options(digits=3)
mod1 <- lm(sat ~ salary, data=SAT)

mod2 <- lm(sat ~ salary + frac, data=SAT)

SAT <- transform(SAT, fracgrp = cut(frac, breaks=c(0, 22, 49, 81),
labels=c("low fraction", "medium fraction", "high fraction")))
xyplot(sat ~ salary, type=c("r", "p"),
               xlab="Average teacher salary (in thousands of $)",
               ylab="State average SAT score", data=SAT)
@
\caption{Association of state average teacher salary with average SAT score}
\label{fig:sat}
\end{center}
\end{figure}


But the real story is hidden behind one of the ``other factors" that we warn students about but do not generally teach how to address!  The proportion of students taking the SAT varies dramatically between states, as do teacher salaries.
In the midwest and plains states, where teacher salaries tend to be lower, relatively few high school students take the SAT exam.  
These are
typically the top students who are planning to attend college out of state, while many others take the
alternative standardized ACT test.  For each of the three groups of states defined by the fraction taking the SAT, the association is 
non-negative.  The net result is that the fraction
taking the SAT is a confounding factor.  

This problem is a continuous example of Simpson's paradox.
Statistical thinking with an appreciation of Simpson's paradox would alert a student to \emph{look for} the hidden confounding variables.
To tackle this problem, students need to know that multivariable modeling exists (but not all aspects
of how it can be utilized).

Within an introductory statistics course, the use of stratification by a potential confounder is easy to implement.
By splitting
states up into groups based on the fraction of
students taking the SAT it is possible to account for this confounder and use 
bivariate methods to assess the relationship for each of the groups.

The scatterplot in Figure \ref{fig:sat2} displays a grouping of
states with 0-22\% of students (``low fraction", top line), 23-49\% of students (``medium fraction", middle line), and
50-81\% (``high fraction", bottom line). The story is clear: there is a positive or flat relationship between teacher salary
and SAT score for each of these groups, but when we average over them, we observe a negative relationship.



\begin{figure}[tpbh]
\begin{center}
<<sat2,fig.height=3.8,fig.width=5.8,echo=FALSE,message=FALSE,warning=FALSE>>=
xyplot(sat ~ salary, type=c("r", "p"), groups=fracgrp, auto.key=TRUE, 
       xlab="Average teacher salary (in thousands of $)", 
       ylab="State average SAT score", data=SAT)
@
\caption{Association after accounting for the fraction of students taking the SAT in that state}
\label{fig:sat2}
\end{center}
\end{figure}

\begin{figure}[tbhp]
<<message=FALSE,echo=FALSE,fig.height=4>>=
require(GGally)
ggpairs(select(SAT, sat, frac, salary))
@
\caption{Matrix of scatterplots for the state-level SAT data}
\label{fig:splom}
\end{figure}

Further light is shed via a matrix of scatterplots (see Figure \ref{fig:splom}): we see that
the fraction of students taking the SAT is negatively associated with the average statewide SAT scores and positively associated with statewide teacher salary.


\marginnote{Another natural approach to understanding of confounding and multivariate thinking is multiple regression.
While this is not a traditional topic included in introductory statistics, an increasing number of textbooks
and courses are incorporating the basic principles (often purely as a descriptive summarization of the data).
In a multiple regression model that controls for the fraction of students taking the SAT variable, the
sign of the slope parameter for teacher salary flips from negative to positive.}  

It's important to have students look for possible confounding factors when the relationship isn't what they expect, but it is also important when the relationship is what is expected.  It's not always possible to stratify by factors (particularly if important confounders are not collected).  

Multivariable thinking is critical to make sense of the observational data around 
us.  
This type of thinking might be introduced in stages:
\begin{enumerate}
\item learn to identify observational studies,
\item explain why randomized assignment to treatment improves the situation,
\item learn to be wary of cause-and-effect conclusions from observational studies,
\item learn to consider potential confounding factors and explain why they might be confounding factors,
\item use simple approaches (such as stratification) to address confounding
\end{enumerate}

If students
do not have exposure to simple tools for disentangling complex relationships, they may dismiss statistics as an old-school
discipline only suitable for small sample inference of randomized studies.


